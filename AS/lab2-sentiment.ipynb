{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Reviews Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1: 482, 0: 481}), Counter({1: 53, 0: 54}), 500)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, dev, test = util.load_datasets_unlabeled_test()\n",
    "X_train, y_train = train\n",
    "X_dev, y_dev = dev\n",
    "from collections import Counter\n",
    "Counter(y_train), Counter(y_dev), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que para la *train* y *dev* tenemos a la clase equilibrada (al rededor de 50% de entradas positivas y negativas), y el conjunto de *dev* tiene el 10% de la cantidad que tiene el conjunto de *train*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 273, 1: 227})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "baseline = pd.read_csv('review_polarity_competition/results_baseline.csv')\n",
    "Counter(baseline['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el conjunto de *test* no tenemos la distribución de positivos y negativos, pero en el *baseline* que tiene al rededor de 86% de accuracy, las categorías están igualmente distribuidas, por lo que se puede asumir que la distribución del conjunto de *test* es igual a la del conjunto de *dev*.\n",
    "\n",
    "### Baseline\n",
    "\n",
    "Ya tenemos los resultados de un modelo como punto de referencia, en donde se logra un *accuracy* del 86%, por lo tanto los prócimos modelos tienen que buscar superar esa performance.\n",
    "\n",
    "### Vectorización\n",
    "\n",
    "Para la vectorización de los datos vamos a probar con `CountVectorizer` y con `TfidfVectorizer`.\n",
    "\n",
    "Para medir la performance de cada vectorizador, vamos a utilizar por el momento el modelo de `LogisticRegression`, con los parámetros por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de parámetros para \"CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\"\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'clf__random_state': 0, 'vect__binary': True, 'vect__max_df': 0.95, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.834 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.837 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.840 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.834 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.837 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.832 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.829 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.828 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.828 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.834 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.833 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.833 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.830 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.836 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.832 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.827 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.828 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.830 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.833 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.839 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.838 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.833 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.836 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.839 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.830 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.831 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.832 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.827 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.826 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.825 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.831 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.819 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.821 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.825 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.818 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.822 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.828 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.827 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.825 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.832 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.821 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.822 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.834 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.817 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.820 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.836 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.828 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.826 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.829 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.826 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.830 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.825 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.823 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.821 (+/-0.000) para los parámetros\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "accuracy\t0.89\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.86      0.93      0.89        54\n",
      "        pos       0.92      0.85      0.88        53\n",
      "\n",
      "avg / total       0.89      0.89      0.89       107\n",
      "\n",
      "[[50  4]\n",
      " [ 8 45]]\n",
      "None\n",
      "\n",
      "# Exploración de parámetros para \"TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\"\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'clf__random_state': 0, 'vect__binary': True, 'vect__max_df': 0.9, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.855 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.856 (+/-0.002) para los parámetros\n",
      "Exactitud: 0.847 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.856 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.852 (+/-0.002) para los parámetros\n",
      "Exactitud: 0.845 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.853 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.848 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.843 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.854 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.856 (+/-0.002) para los parámetros\n",
      "Exactitud: 0.847 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.857 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.853 (+/-0.002) para los parámetros\n",
      "Exactitud: 0.845 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.853 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.847 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.842 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.857 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.857 (+/-0.002) para los parámetros\n",
      "Exactitud: 0.847 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.855 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.853 (+/-0.002) para los parámetros\n",
      "Exactitud: 0.847 (+/-0.002) para los parámetros\n",
      "Exactitud: 0.854 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.847 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.842 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.837 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.830 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.829 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.840 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.831 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.833 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.835 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.830 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.830 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.842 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.837 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.834 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.843 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.839 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.843 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.836 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.836 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.835 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.845 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.847 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.849 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.846 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.849 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.848 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.844 (+/-0.001) para los parámetros\n",
      "Exactitud: 0.841 (+/-0.000) para los parámetros\n",
      "Exactitud: 0.841 (+/-0.001) para los parámetros\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "accuracy\t0.88\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.89      0.87      0.88        54\n",
      "        pos       0.87      0.89      0.88        53\n",
      "\n",
      "avg / total       0.88      0.88      0.88       107\n",
      "\n",
      "[[47  7]\n",
      " [ 6 47]]\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "vects = [\n",
    "    CountVectorizer(),\n",
    "    TfidfVectorizer(),\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "    'vect__binary': [True, False],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vect__min_df': [3, 5, 7],\n",
    "    'vect__max_df': [0.95, 0.9, 0.7],\n",
    "    'clf__random_state': [0],\n",
    "}\n",
    "\n",
    "for vect in vects:\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', LogisticRegression()),\n",
    "    ])\n",
    "    model = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"# Exploración de parámetros para \\\"%s\\\"\" % vect, end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"Mejor conjunto de parámetros:\")\n",
    "    print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "    print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros\" % (mean, std ** 2))\n",
    "    print()\n",
    "    \n",
    "    print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "    print(util.print_eval(model, X_dev, y_dev), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__random_state': 0,\n",
       " 'vect__binary': True,\n",
       " 'vect__max_df': 0.9,\n",
       " 'vect__min_df': 5,\n",
       " 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se observan grandes diferencias en los resultados. Si bien en el conjunto de *dev* se observan mejores resultados para `CountVectorizer`, en el *cross-validation* se pueden ver resultados generales mejores con la vectorización de `TfidfVectorizer`, por lo que optamos por esa forma de vectorizar. \n",
    "\n",
    "### Exploración de Modelo\n",
    "\n",
    "A partir de la mejor forma de vectorización obtenida, vamos a probar diferentes modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.88\tmacro f1\t0.88\n",
      "accuracy\t0.80\tmacro f1\t0.80\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "accuracy\t0.94\tmacro f1\t0.94\n",
      "accuracy\t0.85\tmacro f1\t0.85\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.68\tmacro f1\t0.68\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "accuracy\t0.97\tmacro f1\t0.97\n",
      "accuracy\t0.88\tmacro f1\t0.88\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.85\tmacro f1\t0.85\n",
      "<class 'sklearn.svm.classes.SVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.50\tmacro f1\t0.33\n",
      "accuracy\t0.50\tmacro f1\t0.33\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "accuracy\t0.99\tmacro f1\t0.99\n",
      "accuracy\t0.73\tmacro f1\t0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clfs = [\n",
    "    KNeighborsClassifier(),\n",
    "    MultinomialNB(),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    LogisticRegression(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    SVC(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "]\n",
    "\n",
    "vect = TfidfVectorizer(binary=True,\n",
    "                      max_df=0.9,\n",
    "                      min_df=5,\n",
    "                      ngram_range=(1,1))\n",
    "\n",
    "for clf in clfs:\n",
    "    print(str(clf.__class__))\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', clf),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    util.print_short_eval(pipeline, X_train, y_train)\n",
    "    util.print_short_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de estos resultados vamos ajustando los modelos que mejores resultados dan.\n",
    "\n",
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de parámetros\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'clf__C': 1.0, 'clf__max_iter': 100.0, 'clf__tol': 1e-06}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.830 (+/-0.001) para los parámetros {'clf__C': 0.1, 'clf__max_iter': 100.0, 'clf__tol': 1e-06}\n",
      "Exactitud: 0.830 (+/-0.001) para los parámetros {'clf__C': 0.1, 'clf__max_iter': 100.0, 'clf__tol': 1e-05}\n",
      "Exactitud: 0.830 (+/-0.001) para los parámetros {'clf__C': 0.1, 'clf__max_iter': 100.0, 'clf__tol': 0.0001}\n",
      "Exactitud: 0.830 (+/-0.001) para los parámetros {'clf__C': 0.1, 'clf__max_iter': 1000.0, 'clf__tol': 1e-06}\n",
      "Exactitud: 0.830 (+/-0.001) para los parámetros {'clf__C': 0.1, 'clf__max_iter': 1000.0, 'clf__tol': 1e-05}\n",
      "Exactitud: 0.830 (+/-0.001) para los parámetros {'clf__C': 0.1, 'clf__max_iter': 1000.0, 'clf__tol': 0.0001}\n",
      "Exactitud: 0.857 (+/-0.001) para los parámetros {'clf__C': 1.0, 'clf__max_iter': 100.0, 'clf__tol': 1e-06}\n",
      "Exactitud: 0.857 (+/-0.001) para los parámetros {'clf__C': 1.0, 'clf__max_iter': 100.0, 'clf__tol': 1e-05}\n",
      "Exactitud: 0.857 (+/-0.001) para los parámetros {'clf__C': 1.0, 'clf__max_iter': 100.0, 'clf__tol': 0.0001}\n",
      "Exactitud: 0.857 (+/-0.001) para los parámetros {'clf__C': 1.0, 'clf__max_iter': 1000.0, 'clf__tol': 1e-06}\n",
      "Exactitud: 0.857 (+/-0.001) para los parámetros {'clf__C': 1.0, 'clf__max_iter': 1000.0, 'clf__tol': 1e-05}\n",
      "Exactitud: 0.857 (+/-0.001) para los parámetros {'clf__C': 1.0, 'clf__max_iter': 1000.0, 'clf__tol': 0.0001}\n",
      "Exactitud: 0.852 (+/-0.000) para los parámetros {'clf__C': 10.0, 'clf__max_iter': 100.0, 'clf__tol': 1e-06}\n",
      "Exactitud: 0.852 (+/-0.000) para los parámetros {'clf__C': 10.0, 'clf__max_iter': 100.0, 'clf__tol': 1e-05}\n",
      "Exactitud: 0.852 (+/-0.000) para los parámetros {'clf__C': 10.0, 'clf__max_iter': 100.0, 'clf__tol': 0.0001}\n",
      "Exactitud: 0.852 (+/-0.000) para los parámetros {'clf__C': 10.0, 'clf__max_iter': 1000.0, 'clf__tol': 1e-06}\n",
      "Exactitud: 0.852 (+/-0.000) para los parámetros {'clf__C': 10.0, 'clf__max_iter': 1000.0, 'clf__tol': 1e-05}\n",
      "Exactitud: 0.852 (+/-0.000) para los parámetros {'clf__C': 10.0, 'clf__max_iter': 1000.0, 'clf__tol': 0.0001}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "accuracy\t0.88\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.89      0.87      0.88        54\n",
      "        pos       0.87      0.89      0.88        53\n",
      "\n",
      "avg / total       0.88      0.88      0.88       107\n",
      "\n",
      "[[47  7]\n",
      " [ 6 47]]\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'clf__tol' : np.logspace(-6,-4,3),\n",
    "    'clf__C' : np.logspace(-1,1,3),\n",
    "    'clf__max_iter' : np.logspace(2,3,2)\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('clf', LogisticRegression(random_state=0)),\n",
    "])\n",
    "model = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"# Exploración de parámetros\", end=\"\\n\\n\")\n",
    "\n",
    "print(\"Mejor conjunto de parámetros:\")\n",
    "print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "    print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros %r\" % (mean, std ** 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "print(util.print_eval(model, X_dev, y_dev), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'logreg.p'\n",
    "f = open(filename, 'wb')\n",
    "pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de parámetros\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'clf__C': 0.1, 'clf__tol': 1e-06}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.826 (+/-0.001) para los parámetros {'clf__C': 0.01, 'clf__tol': 1e-06}\n",
      "Exactitud: 0.826 (+/-0.001) para los parámetros {'clf__C': 0.01, 'clf__tol': 1e-05}\n",
      "Exactitud: 0.826 (+/-0.001) para los parámetros {'clf__C': 0.01, 'clf__tol': 0.0001}\n",
      "Exactitud: 0.856 (+/-0.001) para los parámetros {'clf__C': 0.1, 'clf__tol': 1e-06}\n",
      "Exactitud: 0.856 (+/-0.001) para los parámetros {'clf__C': 0.1, 'clf__tol': 1e-05}\n",
      "Exactitud: 0.856 (+/-0.001) para los parámetros {'clf__C': 0.1, 'clf__tol': 0.0001}\n",
      "Exactitud: 0.854 (+/-0.000) para los parámetros {'clf__C': 1.0, 'clf__tol': 1e-06}\n",
      "Exactitud: 0.854 (+/-0.000) para los parámetros {'clf__C': 1.0, 'clf__tol': 1e-05}\n",
      "Exactitud: 0.854 (+/-0.000) para los parámetros {'clf__C': 1.0, 'clf__tol': 0.0001}\n",
      "Exactitud: 0.838 (+/-0.001) para los parámetros {'clf__C': 10.0, 'clf__tol': 1e-06}\n",
      "Exactitud: 0.838 (+/-0.001) para los parámetros {'clf__C': 10.0, 'clf__tol': 1e-05}\n",
      "Exactitud: 0.838 (+/-0.001) para los parámetros {'clf__C': 10.0, 'clf__tol': 0.0001}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "accuracy\t0.88\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.89      0.87      0.88        54\n",
      "        pos       0.87      0.89      0.88        53\n",
      "\n",
      "avg / total       0.88      0.88      0.88       107\n",
      "\n",
      "[[47  7]\n",
      " [ 6 47]]\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'clf__tol' : np.logspace(-6,-4,3),\n",
    "    'clf__C' : np.logspace(-2,1,4),\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "model = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"# Exploración de parámetros\", end=\"\\n\\n\")\n",
    "\n",
    "print(\"Mejor conjunto de parámetros:\")\n",
    "print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "    print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros %r\" % (mean, std ** 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "print(util.print_eval(model, X_dev, y_dev), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'linearsvc.p'\n",
    "f = open(filename, 'wb')\n",
    "pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de parámetros\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'clf__criterion': 'entropy', 'clf__max_features': 50, 'clf__n_estimators': 500}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.757 (+/-0.001) para los parámetros {'clf__criterion': 'gini', 'clf__max_features': 'sqrt', 'clf__n_estimators': 100}\n",
      "Exactitud: 0.777 (+/-0.001) para los parámetros {'clf__criterion': 'gini', 'clf__max_features': 'sqrt', 'clf__n_estimators': 500}\n",
      "Exactitud: 0.775 (+/-0.002) para los parámetros {'clf__criterion': 'gini', 'clf__max_features': 'sqrt', 'clf__n_estimators': 1000}\n",
      "Exactitud: 0.752 (+/-0.001) para los parámetros {'clf__criterion': 'gini', 'clf__max_features': 'log2', 'clf__n_estimators': 100}\n",
      "Exactitud: 0.767 (+/-0.002) para los parámetros {'clf__criterion': 'gini', 'clf__max_features': 'log2', 'clf__n_estimators': 500}\n",
      "Exactitud: 0.763 (+/-0.002) para los parámetros {'clf__criterion': 'gini', 'clf__max_features': 'log2', 'clf__n_estimators': 1000}\n",
      "Exactitud: 0.759 (+/-0.001) para los parámetros {'clf__criterion': 'gini', 'clf__max_features': 10, 'clf__n_estimators': 100}\n",
      "Exactitud: 0.778 (+/-0.002) para los parámetros {'clf__criterion': 'gini', 'clf__max_features': 10, 'clf__n_estimators': 500}\n",
      "Exactitud: 0.762 (+/-0.002) para los parámetros {'clf__criterion': 'gini', 'clf__max_features': 10, 'clf__n_estimators': 1000}\n",
      "Exactitud: 0.756 (+/-0.001) para los parámetros {'clf__criterion': 'gini', 'clf__max_features': 50, 'clf__n_estimators': 100}\n",
      "Exactitud: 0.774 (+/-0.003) para los parámetros {'clf__criterion': 'gini', 'clf__max_features': 50, 'clf__n_estimators': 500}\n",
      "Exactitud: 0.776 (+/-0.002) para los parámetros {'clf__criterion': 'gini', 'clf__max_features': 50, 'clf__n_estimators': 1000}\n",
      "Exactitud: 0.766 (+/-0.001) para los parámetros {'clf__criterion': 'entropy', 'clf__max_features': 'sqrt', 'clf__n_estimators': 100}\n",
      "Exactitud: 0.787 (+/-0.001) para los parámetros {'clf__criterion': 'entropy', 'clf__max_features': 'sqrt', 'clf__n_estimators': 500}\n",
      "Exactitud: 0.791 (+/-0.001) para los parámetros {'clf__criterion': 'entropy', 'clf__max_features': 'sqrt', 'clf__n_estimators': 1000}\n",
      "Exactitud: 0.766 (+/-0.002) para los parámetros {'clf__criterion': 'entropy', 'clf__max_features': 'log2', 'clf__n_estimators': 100}\n",
      "Exactitud: 0.781 (+/-0.002) para los parámetros {'clf__criterion': 'entropy', 'clf__max_features': 'log2', 'clf__n_estimators': 500}\n",
      "Exactitud: 0.783 (+/-0.002) para los parámetros {'clf__criterion': 'entropy', 'clf__max_features': 'log2', 'clf__n_estimators': 1000}\n",
      "Exactitud: 0.774 (+/-0.001) para los parámetros {'clf__criterion': 'entropy', 'clf__max_features': 10, 'clf__n_estimators': 100}\n",
      "Exactitud: 0.783 (+/-0.002) para los parámetros {'clf__criterion': 'entropy', 'clf__max_features': 10, 'clf__n_estimators': 500}\n",
      "Exactitud: 0.782 (+/-0.002) para los parámetros {'clf__criterion': 'entropy', 'clf__max_features': 10, 'clf__n_estimators': 1000}\n",
      "Exactitud: 0.783 (+/-0.001) para los parámetros {'clf__criterion': 'entropy', 'clf__max_features': 50, 'clf__n_estimators': 100}\n",
      "Exactitud: 0.792 (+/-0.001) para los parámetros {'clf__criterion': 'entropy', 'clf__max_features': 50, 'clf__n_estimators': 500}\n",
      "Exactitud: 0.787 (+/-0.002) para los parámetros {'clf__criterion': 'entropy', 'clf__max_features': 50, 'clf__n_estimators': 1000}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "accuracy\t0.84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.86      0.81      0.84        54\n",
      "        pos       0.82      0.87      0.84        53\n",
      "\n",
      "avg / total       0.84      0.84      0.84       107\n",
      "\n",
      "[[44 10]\n",
      " [ 7 46]]\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'clf__n_estimators' : [100, 500, 1000],\n",
    "    'clf__criterion' : ['gini', 'entropy'],\n",
    "    'clf__max_features' : ['sqrt', 'log2', 10, 50]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('clf', RandomForestClassifier(random_state=0)),\n",
    "])\n",
    "model = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"# Exploración de parámetros\", end=\"\\n\\n\")\n",
    "\n",
    "print(\"Mejor conjunto de parámetros:\")\n",
    "print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "    print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros %r\" % (mean, std ** 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "print(util.print_eval(model, X_dev, y_dev), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'randomforest.p'\n",
    "f = open(filename, 'wb')\n",
    "pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de parámetros\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'clf__alpha': 0.9}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.850 (+/-0.000) para los parámetros {'clf__alpha': 1}\n",
      "Exactitud: 0.848 (+/-0.001) para los parámetros {'clf__alpha': 0.7}\n",
      "Exactitud: 0.852 (+/-0.000) para los parámetros {'clf__alpha': 0.9}\n",
      "Exactitud: 0.852 (+/-0.000) para los parámetros {'clf__alpha': 0.95}\n",
      "Exactitud: 0.852 (+/-0.000) para los parámetros {'clf__alpha': 0.85}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "accuracy\t0.85\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.83      0.89      0.86        54\n",
      "        pos       0.88      0.81      0.84        53\n",
      "\n",
      "avg / total       0.85      0.85      0.85       107\n",
      "\n",
      "[[48  6]\n",
      " [10 43]]\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'clf__alpha' : [1, 0.7, 0.9, 0.95, 0.85],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "model = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"# Exploración de parámetros\", end=\"\\n\\n\")\n",
    "\n",
    "print(\"Mejor conjunto de parámetros:\")\n",
    "print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "    print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros %r\" % (mean, std ** 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "print(util.print_eval(model, X_dev, y_dev), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'multi.p'\n",
    "f = open(filename, 'wb')\n",
    "pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de parámetros\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'clf__algorithm': 'brute', 'clf__n_neighbors': 50, 'clf__weights': 'distance'}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.737 (+/-0.002) para los parámetros {'clf__algorithm': 'brute', 'clf__n_neighbors': 2, 'clf__weights': 'distance'}\n",
      "Exactitud: 0.769 (+/-0.001) para los parámetros {'clf__algorithm': 'brute', 'clf__n_neighbors': 5, 'clf__weights': 'distance'}\n",
      "Exactitud: 0.794 (+/-0.001) para los parámetros {'clf__algorithm': 'brute', 'clf__n_neighbors': 10, 'clf__weights': 'distance'}\n",
      "Exactitud: 0.813 (+/-0.000) para los parámetros {'clf__algorithm': 'brute', 'clf__n_neighbors': 15, 'clf__weights': 'distance'}\n",
      "Exactitud: 0.815 (+/-0.001) para los parámetros {'clf__algorithm': 'brute', 'clf__n_neighbors': 20, 'clf__weights': 'distance'}\n",
      "Exactitud: 0.832 (+/-0.001) para los parámetros {'clf__algorithm': 'brute', 'clf__n_neighbors': 30, 'clf__weights': 'distance'}\n",
      "Exactitud: 0.840 (+/-0.001) para los parámetros {'clf__algorithm': 'brute', 'clf__n_neighbors': 40, 'clf__weights': 'distance'}\n",
      "Exactitud: 0.841 (+/-0.002) para los parámetros {'clf__algorithm': 'brute', 'clf__n_neighbors': 50, 'clf__weights': 'distance'}\n",
      "Exactitud: 0.836 (+/-0.002) para los parámetros {'clf__algorithm': 'brute', 'clf__n_neighbors': 60, 'clf__weights': 'distance'}\n",
      "Exactitud: 0.830 (+/-0.002) para los parámetros {'clf__algorithm': 'brute', 'clf__n_neighbors': 70, 'clf__weights': 'distance'}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "accuracy\t0.86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.85      0.87      0.86        54\n",
      "        pos       0.87      0.85      0.86        53\n",
      "\n",
      "avg / total       0.86      0.86      0.86       107\n",
      "\n",
      "[[47  7]\n",
      " [ 8 45]]\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'clf__n_neighbors' : [2, 5, 10, 15, 20, 30, 40, 50, 60, 70],\n",
    "    'clf__weights' : ['distance'],\n",
    "    'clf__algorithm' : ['brute'],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('clf', KNeighborsClassifier()),\n",
    "])\n",
    "model = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"# Exploración de parámetros\", end=\"\\n\\n\")\n",
    "\n",
    "print(\"Mejor conjunto de parámetros:\")\n",
    "print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "    print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros %r\" % (mean, std ** 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "print(util.print_eval(model, X_dev, y_dev), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'knn.p'\n",
    "f = open(filename, 'wb')\n",
    "pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble\n",
    "\n",
    "A partir de los modelos generados se pretende analizar los resultados de considerarlos a todos los modelos con algún método de *ensemble* como `VotingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"logreg.p\",'rb')\n",
    "logreg = pickle.load(file)\n",
    "file = open(\"linearsvc.p\",'rb')\n",
    "linearsvc = pickle.load(file)\n",
    "file = open(\"randomforest.p\",'rb')\n",
    "randomforest = pickle.load(file)\n",
    "file = open(\"multi.p\",'rb')\n",
    "multi = pickle.load(file)\n",
    "file = open(\"knn.p\",'rb')\n",
    "knn = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de parámetros\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'weights': [5, 4, 1, 3, 2]}\n",
      "\n",
      "Exactitud: 0.849 (+/-0.001) para los parámetros {'weights': [5, 4, 1, 3, 2]}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "accuracy\t0.88\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.89      0.87      0.88        54\n",
      "        pos       0.87      0.89      0.88        53\n",
      "\n",
      "avg / total       0.88      0.88      0.88       107\n",
      "\n",
      "[[47  7]\n",
      " [ 6 47]]\n",
      "None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'weights' : [[5, 4, 1, 3, 2]],\n",
    "}\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[('logreg', logreg), ('linearsvc', linearsvc), ('randomforest', randomforest), ('multi', multi), ('knn', knn)],\n",
    "                         voting='hard')\n",
    "model = GridSearchCV(ensemble, param_grid, cv=5, scoring='accuracy')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"# Exploración de parámetros\", end=\"\\n\\n\")\n",
    "\n",
    "print(\"Mejor conjunto de parámetros:\")\n",
    "print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "    print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros %r\" % (mean, std ** 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "print(util.print_eval(model, X_dev, y_dev), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/anaconda2/envs/as-kaggle/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "util.save_results('results4.csv', model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
